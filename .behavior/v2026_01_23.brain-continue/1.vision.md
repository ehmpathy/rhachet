# vision: brain-continue

illustrates the experience for folks who use episode and series continuation

---

## 1. who uses this?

### persona: skill author

builds reusable thought routes (skills) that leverage brains for analysis, generation, or orchestration.

**goals:**
- separate setup from execution (enroll brain with instructions, then process content)
- build multi-step workflows (analyze → decide → act)
- create branch thought routes (explore alternatives from a checkpoint)

**pain without continuation:**
- must re-send full context on every call (token waste, latency)
- cannot checkpoint and branch (must restart from scratch)
- cannot build stateful reviewers, tutors, or assistants

### persona: actor consumer

uses actors (brain + role) via `.ask()` and `.act()` for domain tasks.

**goals:**
- have conversations that remember prior context
- build workflows where each step informs the next
- avoid the need to repeat instructions or context

**pain without continuation:**
- each `.ask()` starts fresh (no memory)
- must manually manage message history
- complex workflows require custom orchestration

---

## 2. what do they want to do?

### usecase A: stateful reviewer (BrainAtom)

> "i want to set up a reviewer with rules, then feed it content to review"

```ts
// step 1: enroll the brain with review instructions
const { episode: setup, output } = await atom.ask({
  say: `you are a code reviewer. here are the rules:
    - flag any function over 50 lines
    - require error handle on all async calls
    - prefer arrow functions
    reply { understood: true } if you understood`,
});

// step 2: feed content to review (brain remembers the rules)
// note: returns NEW episode ref; setup ref remains valid for other reviews
const { episode: afterReview, output: review } = await atom.ask({
  on: { episode: setup },
  say: `review this code:\n\n${codeContent}`,
});

// step 3: review more content (can build on setup OR afterReview)
const { output: review2 } = await atom.ask({
  on: { episode: setup },  // branch from setup (review1 not in context)
  say: `review this other code:\n\n${otherContent}`,
});
```

**without continuation:** must re-send rules with every review request.

### usecase B: multi-step workflow (BrainRepl)

> "i want to analyze, then decide, then act — with each step informed by prior steps"

```ts
// step 1: analyze
const { series: s0, output: analysis } = await repl.ask({
  say: `analyze this codebase for security issues: ${files}`,
});

// step 2: decide (brain remembers the analysis)
const { series: s1, output: plan } = await repl.ask({
  on: { series: s0 },
  say: 'prioritize the issues by severity and create a fix plan',
});

// step 3: act (brain remembers both analysis and plan)
const { output: fixes } = await repl.ask({
  on: { series: s1 },
  say: 'implement the highest priority fixes',
});
```

**without continuation:** must re-send analysis and plan with each step.

### usecase C: branch exploration (BrainAtom)

> "i want to explore two different approaches from the same start point"

```ts
// setup: establish shared context
const { episode: checkpoint, output } = await atom.ask({
  say: `here is the problem: ${problemDescription}`,
});

// branch A: explore solution via refactor
const { output: approachA } = await atom.ask({
  on: { episode: checkpoint },
  say: 'solve this via refactor of the current code',
});

// branch B: explore solution via rewrite (same start point)
const { output: approachB } = await atom.ask({
  on: { episode: checkpoint },
  say: 'solve this via rewrite from scratch',
});

// compare approaches
```

**without continuation:** cannot branch from the same context.

### usecase C': branch exploration (BrainRepl)

> "i want to explore two different implementation approaches from the same context"

```ts
// setup: establish shared context with file reads
const { episode: checkpoint } = await repl.ask({
  say: `analyze this codebase: ${files}`,
});

// branch A: implement via refactor (from checkpoint)
const { output: implA } = await repl.ask({
  on: { episode: checkpoint },
  say: 'implement the fix via refactor',
});

// branch B: implement via rewrite (from same checkpoint)
const { output: implB } = await repl.ask({
  on: { episode: checkpoint },
  say: 'implement the fix via rewrite',
});
```

### usecase D: independent thoughts on same thread (BrainAtom)

> "i want to ask multiple unrelated questions as part of one operation"

```ts
// independent episodes — no context bleed
const { episode: ep1, output: catBrief } = await atom.ask({
  say: 'what is a cat?',
});

const { episode: ep2, output: dogBrief } = await atom.ask({
  say: 'what is a dog?',
});

// synthesize in new episode (receives artifacts, not context)
const { output: petBrief } = await atom.ask({
  say: `given these briefs, what is a pet?\n\ncat: ${catBrief}\n\ndog: ${dogBrief}`,
});
```

**key insight:** independent episodes prevent context bleed. the pet question receives artifacts, not accumulated context.

### usecase E: cross-supplier continuation

> "i want to triage with consensus, then escalate to a capable model"

```ts
// cluster the security concerns by domain
const { episode: clustered } = await capableAtom.ask({
  say: `cluster these security concerns by domain: ${concerns}`,
});

// fanout: triage with multiple cheap atoms for consensus
const severitySchema = z.object({
  severity: z.enum(['critical', 'high', 'medium', 'low']),
  rationale: z.string(),
});
const opinions = await Promise.all([
  cheapAnthropicAtom.ask({
    on: { episode: clustered },
    say: 'rate severity',
    schema: { output: severitySchema },
  }),
  cheapOpenaiAtom.ask({
    on: { episode: clustered },
    say: 'rate severity',
    schema: { output: severitySchema },
  }),
  cheapGeminiAtom.ask({
    on: { episode: clustered },
    say: 'rate severity',
    schema: { output: severitySchema },
  }),
]);

// count consensus
const criticalVotes = opinions.filter(o => o.output.severity === 'critical').length;

// no critical votes: done
if (criticalVotes === 0) return;

// otherwise, summarize the critical concerns
const { episode: summarized, output: summary } = await capableAtom.ask({
  on: { episode: clustered },
  say: `summarize the critical security concerns; ${opinions.map(opinion => opinion.output)}`,
});

// if 1 vote: alert for human review
if (criticalVotes === 1)
  await alertForReview({ summary });

// if 2+ votes: escalate to capable repl immediately
if (criticalVotes >= 2)
  await capableRepl.act({
    on: { episode: summarized },
    do: 'fix the critical security issues',
  });
```

**key insight:** episodes and series are rhachet-prescribed serializable constructs, not supplier-specific. fanout across suppliers for consensus, then continue on any supplier for action.

**without continuation:** must re-send the full context to each supplier manually.

---

## 3. what contracts do they engage with?

### BrainAtom contract

```ts
// input
brain.ask({
  on?: { episode: BrainEpisode },  // build on prior episode
  say: string,                      // the prompt
  schema?: { output: z.Schema },    // structured output
});

// output
{
  episode: BrainEpisode,  // NEW episode reference (immutable checkpoint)
  output: TOutput,        // the brain's response
}
```

**episode immutability:** each `.ask()` returns a NEW episode reference. the prior episode ref remains valid and unchanged — it captures context at that moment in time. this enables both fanout (branch to explore alternatives) and revive (resume from prior checkpoint).

### BrainRepl contract

```ts
// input
repl.ask({
  on?: PickOne<{
    episode: BrainEpisode,  // build on prior episode (branch/revive)
    series: BrainSeries,    // build on prior series (linear continuation)
  }>,
  say: string,
  schema?: { output: z.Schema },
});

// output
{
  series: BrainSeries,    // NEW series reference (immutable checkpoint)
  episode: BrainEpisode,  // NEW episode reference (immutable checkpoint)
  output: TOutput,
}
```

**immutability:** each `.ask()` returns NEW series AND episode references. both are immutable checkpoints — prior refs remain valid for later branches or revives. series = checkpoint on the long timeline; episode = checkpoint within a context window.

---

## 4. how do they talk about it?

### user vocabulary → rhachet vocabulary

| what they say  | what we call it                       | why                                              |
| -------------- | ------------------------------------- | ------------------------------------------------ |
| "turn"         | BrainExchange                         | could mean one side; we mean both sides together |
| "message"      | BrainExchange                         | could mean one side; we mean both sides together |
| "conversation" | BrainEpisode                          | could mean episode or series; we map to episode  |
| "session"      | BrainSeries                           | could mean episode or series; we map to series   |
| "thread"       | BrainSeries                           | could mean episode or series; we map to series   |
| "continue"     | `on: { episode }` or `on: { series }` | pass prior ref to build on it                    |
| "start fresh"  | omit `on`                             | no ref = new episode/series                      |
| "branch"       | `on: { episode }` on prior ref        | return to a saved point, explore a new path      |
| "checkpoint"   | episode reference                     | a saved moment you can return to                 |
| "save"         | store episode ref in variable         | capture the ref that `.ask()` returns            |
| "revive"       | `on: { episode }` on saved ref        | go back to before something went wrong           |

### vocabulary we avoid

| term           | why we avoid it                              | what we use instead               |
| -------------- | -------------------------------------------- | --------------------------------- |
| "conversation" | unclear: episode or series?                  | episode or series                 |
| "session"      | unclear: episode or series?                  | episode or series                 |
| "thread"       | unclear: episode or series?                  | episode or series                 |
| "turn"         | implies one party; exchange is bidirectional | exchange                          |
| "context"      | ambiguous (context window? context object?)  | episode (bounded context window)  |
| "message"      | ambiguous (user? brain? both?)               | exchange (explicit bidirectional) |

**note:** we prefer to use the most semantically precise and intuitive term, to eliminate ambiguity and avoid semantically diffused terms.

---

## 5. what timelines do they go through?

### timeline A: simple continuation (BrainAtom)

```
t0: atom.ask({ say: 'setup instructions' })
    → ep0 created, brain enrolled

t1: atom.ask({ on: { episode: ep0 }, say: 'do the task' })
    → NEW ep1 returned, task executed with ep0 context
    → ep0 remains valid (immutable)

t2: atom.ask({ on: { episode: ep1 }, say: 'followup question' })
    → NEW ep2 returned, followup answered with ep0+ep1 context
    → ep0 and ep1 both remain valid (can branch from either)
```

### timeline B: series with compaction (BrainRepl)

```
t0: const { series: s0 } = await repl.ask({ say: 'start long task' })
    │
    ├── t0.0: repl loops internally (tool use)
    ├── t0.1: repl loops internally (tool use)
    ├── ...
    ├── t0.N: context window full, repl compacts internally
    ├── t0.N+1: repl loops internally (tool use)
    ├── ...
    └── t0.M: repl completes
              → returns { series: s0, episode, output }
              → repl retains only latest refs (memory efficient)

t1: const { series: s1 } = await repl.ask({ on: { series: s0 }, say: 'continue' })
    │
    ├── t1.0: repl loops internally (tool use)
    ├── ...
    ├── t1.K: context window full, repl compacts internally
    ├── ...
    └── t1.L: repl completes
              → returns { series: s1, episode, output }

t2: const { series: s2 } = await repl.ask({ on: { series: s1 }, say: 'finish up' })
    → ...
```

**note:** compaction happens internally within a single `.ask()` call when the repl's tool-use loop fills the context window. the caller only sees the final series and episode refs on return.

### timeline B': ask then act with approval (BrainRepl)

```
t0: const { series: s0, output: plan } = await repl.ask({ say: 'plan the refactor' })
    → repl analyzes, returns a plan

t1: // caller reviews plan, gets human approval
    const approved = await getHumanApproval({ plan });

t2: const { series: s1 } = await repl.act({ on: { series: s0 }, do: 'execute the plan' })
    → continues on s0, brain remembers the plan from prior context
    → executes the refactor
```

**note:** `.ask()` and `.act()` can both continue a series. the brain retains context from prior exchanges, so t2 knows the plan without the caller needing to resend it.

### timeline C: branch exploration (BrainAtom)

```
t0: const { episode: e0 } = await atom.ask({ say: 'problem description' })

t1a: const { output: approachA } = await atom.ask({ on: { episode: e0 }, say: 'try approach A' })
     → e0 remains valid (immutable)

t1b: const { output: approachB } = await atom.ask({ on: { episode: e0 }, say: 'try approach B' })
     → same start point as t1a

t2: compare approachA vs approachB, choose best
```

### timeline D: branch implementation (BrainRepl)

```
t0: const { episode: e0 } = await repl.ask({ say: 'analyze codebase' })

t1a: const { output: implA } = await repl.ask({ on: { episode: e0 }, say: 'implement via refactor' })
     → e0 remains valid (immutable)

t1b: const { output: implB } = await repl.ask({ on: { episode: e0 }, say: 'implement via rewrite' })
     → same start point as t1a

t2: compare implA vs implB, merge preferred
```

### timeline E: cross-supplier continuation

```
t0: const { episode: e0 } = await anthropicAtom.ask({ say: 'analyze security issues' })
    → episode created (plaintext exchanges)

t1: const { output: review } = await openaiAtom.ask({ on: { episode: e0 }, say: 'add gaps' })
    → e0 exchanges passed to openai as plaintext
    → openai sees full prior context

t2: const { output: secrets } = await localAtom.ask({ on: { episode: e0 }, say: 'check for secrets' })
    → e0 exchanges passed to local model as plaintext
    → local model sees full prior context
```

**note:** episodes and series are rhachet-prescribed serializable constructs. no translation needed — the same exchanges work with any supplier.

---

## 6. how well does it solve their goals?

| goal                          | solution                                                          | fit       |
| ----------------------------- | ----------------------------------------------------------------- | --------- |
| separate setup from execution | episode continuation preserves setup context                      | ✓ perfect |
| multi-step workflows          | series continuation chains steps with shared context              | ✓ perfect |
| branch exploration            | episode refs are time-capsules for branch                         | ✓ perfect |
| avoid context bleed           | independent episodes (without `on`) are isolated                  | ✓ perfect |
| handle long conversations     | series compaction bridges context windows                         | ✓ perfect |
| cross-supplier continuation   | episodes and series are rhachet-prescribed, not supplier-specific | ✓ perfect |
| simple mental model           | two concepts: episode (context window) and series (chain)         | ✓ simple  |

---

## 7. edge cases and pit of success

### edge: attempt to specify both episode and series

```ts
// user attempts to specify both
await repl.ask({ on: { episode, series }, say: '...' });

// pit of success: type error at compile time
// → PickOne<{ episode, series }> prevents both from specified
```

### edge: brain supplier does not support continuation

not every brain supplier will support continuation. that's okay — they can fail fast.

```ts
// user attempts to continue on a supplier that lacks continuation support
await limitedAtom.ask({ on: { episode: priorEpisode }, say: '...' });

// pit of success: error clearly indicates lack of support
// → "continuation not supported by this brain supplier"
```

**recovery paths:**

since every `.ask()` returns episode and series refs, callers have options:

1. **manual recovery** — persist the emitted refs, switch to a supported brain, resume
   ```ts
   const { episode, output } = await limitedAtom.ask({ say: 'analyze' });
   // limitedAtom doesn't support continuation, but we have the episode
   // switch to a capable brain and continue
   const { output: continued } = await capableAtom.ask({
     on: { episode },
     say: 'continue the analysis',
   });
   ```

2. **automatic recovery via context** — context can emit refs to logs by default
   ```ts
   // context.log receives all episode/series refs automatically
   // if a brain fails, ops can recover from logged refs
   ```

**key insight:** the contract requires emission of episodes and series on every response. this enables recovery even when some brains have limited capabilities. the pit of success is preserved — callers always have the refs they need to resume elsewhere.

---

## 7b. patterns enabled by episode immutability

### pattern: fanout

branch from a single checkpoint to explore multiple paths in parallel.

```ts
// save the checkpoint
const { episode: checkpoint } = await atom.ask({ say: problemDescription });

// fanout: parallel branches from same checkpoint
const branches = await Promise.all([
  atom.ask({ on: { episode: checkpoint }, say: 'solve via refactor' }),
  atom.ask({ on: { episode: checkpoint }, say: 'solve via rewrite' }),
  atom.ask({ on: { episode: checkpoint }, say: 'solve via workaround' }),
]);

// compare outputs, choose best approach
const best = selectBest(branches.map(b => b.output));
```

each branch sees the same prior context (checkpoint) but diverges from there.

### pattern: revive

resume from a prior checkpoint when a later exchange goes wrong.

```ts
const checkpoints: Record<string, BrainEpisode> = {};

// save checkpoints at critical moments
const { episode } = await atom.ask({ say: 'setup' });
checkpoints['after-setup'] = episode;

const { episode: ep2 } = await atom.ask({ on: { episode }, say: 'analysis' });
checkpoints['after-analysis'] = ep2;

// risky operation
const { output } = await atom.ask({ on: { episode: ep2 }, say: 'risky op' });

// if output is problematic, revive from before
if (isProblematic(output)) {
  const { output: retry } = await atom.ask({
    on: { episode: checkpoints['after-analysis'] },
    say: 'safer alternative op',
  });
}
```

the brain sees context up to the saved checkpoint — later exchanges are forgotten.

---

## 8. contracts summary

### start fresh

```ts
// BrainAtom: new episode
const { episode, output } = await brain.ask({ say: '...' });

// BrainRepl: new series + episode
const { series, episode, output } = await repl.ask({ say: '...' });
```

### continue linearly

```ts
// BrainAtom: continue episode
const { output } = await brain.ask({ on: { episode }, say: '...' });

// BrainRepl: continue series
const { output } = await repl.ask({ on: { series }, say: '...' });
```

### branch or resume

```ts
// BrainAtom: branch from checkpoint
const { output } = await brain.ask({ on: { episode: checkpoint }, say: '...' });

// BrainRepl: branch from prior episode
const { output } = await repl.ask({ on: { episode: priorEpisode }, say: '...' });
```

**key insight:** every `.ask()` returns NEW refs. prior refs remain valid — they are immutable checkpoints. capture refs only when you need to save checkpoints.

---

## 9. the core insight

> **both episodes and series are timelines — at different scales.**

- an episode is a timeline within a context window
- a series is a timeline across context windows (bridged by compaction)

> **both are immutable time-capsules.**

- each `.ask()` returns NEW series AND episode references
- prior refs remain valid and unchanged
- this enables fanout (branch from any checkpoint) and revive (resume from prior state)

users can:
- **continue linearly** via series (forward on the long timeline)
- **branch or resume** via episode or series (return to any point on either timeline)
- **start fresh** without `on` (new timeline)

this model handles:
- simple conversations (episode continuation)
- long workflows (series with compaction)
- exploratory branches (series or episode checkpoints)
- independent thoughts (separate episodes)
- error recovery (revive from prior checkpoint)

all with two simple concepts, one clear contract, and immutable refs.
