# Feasibility Assessment v2: Harnessing SOTA Agents (Claude CLI) in Rhachet

## Executive Summary: **HIGHLY FEASIBLE** âœ“

After exploring the rhachet codebase and examining the actual `claude` CLI capabilities, I can confidently say that harnessing Claude (and similar SOTA agents) within rhachet is **technically straightforward and architecturally aligned**.

The `claude` CLI's `--print` mode was specifically designed for programmatic invocation, making this integration scenario a natural fit.

---

## Critical Discovery: `--print` Mode

The `claude` CLI has a **non-interactive mode** (`--print`) specifically designed for automation and scripting:

```bash
claude --print "Your prompt here"
```

This single flag makes the entire integration feasible. Combined with other options, we have precise control over agent behavior.

---

## Key CLI Capabilities for Constrained Context

### 1. **Non-Interactive Execution**
```bash
claude --print "Review this code for security issues"
```
- Returns output and exits
- Perfect for programmatic invocation
- Suitable for rhachet's stitcher architecture

### 2. **Structured Output Formats**
```bash
claude --print --output-format json "Explain this code"
```
- `text` (default): Plain text output
- `json`: Structured response with usage stats
- `stream-json`: Real-time streaming updates

**Impact**: Easy deprompting/parsing for rhachet's `Stitch` objects

### 3. **Tool Restrictions**
```bash
# Disable all tools
claude --print --tools "" "What is TypeScript?"

# Allow specific tools only
claude --print --allowed-tools "Bash(ls:*)" "List files"

# Disallow specific tools
claude --print --disallowed-tools "Bash(git:*) Edit" "Review code"
```

**Impact**: Precise control over agent capabilities in constrained contexts

### 4. **Permission Modes for Sandboxing**
```bash
# Bypass permissions in sandboxed environments
claude --print --dangerously-skip-permissions "Analyze code"

# Different permission modes
claude --print --permission-mode plan "Design architecture"
```

**Impact**: The `--dangerously-skip-permissions` flag is **explicitly designed for sandboxed environments** (Docker, etc.)

### 5. **Custom System Prompts**
```bash
claude --print --system-prompt "You are a security reviewer. Focus on vulnerabilities." "Review this code"

# Or append to default prompt
claude --print --append-system-prompt "Be concise. Output only BLOCKERS and NITPICKS." "Review"
```

**Impact**: Can inject rhachet role context (traits, purpose, skills) directly

### 6. **Directory Access Control**
```bash
claude --print --add-dir /path/to/briefs --add-dir /path/to/workspace "Analyze codebase"
```

**Impact**: Constrain filesystem access to specific directories

### 7. **Session Management**
```bash
# Multi-turn conversations with state
claude --print --session-id $UUID "First question"
claude --print --session-id $UUID "Follow-up question"
```

**Impact**: Enables stateful thought routes (prepare â†’ review â†’ release)

---

## Answering the Core Question: Constrained Context Execution

### âœ“ Docker Container Isolation

**YES - Fully Supported**

```bash
docker run \
  -v $(pwd)/.behavior:/app/.behavior:ro \
  -v $(pwd)/workspace:/app/workspace \
  -e ANTHROPIC_API_KEY=$ANTHROPIC_API_KEY \
  -w /app/workspace \
  anthropic/claude-cli:latest \
  claude --print \
    --dangerously-skip-permissions \
    --add-dir /app/.behavior \
    --add-dir /app/workspace \
    --system-prompt "$(cat /app/.behavior/role.md)" \
    "Your ask here"
```

**What this achieves:**
- âœ“ Isolated filesystem (only mounted directories accessible)
- âœ“ No permission dialogs (`--dangerously-skip-permissions`)
- âœ“ Brief context available at `/app/.behavior`
- âœ“ Workspace for artifact generation
- âœ“ Complete reproducibility

### âœ“ Process-Level Isolation (OpenEnv / chroot)

**YES - Multiple Approaches**

**Approach 1: Working Directory + Tool Restrictions**
```typescript
import { execSync } from 'child_process';

const result = execSync(
  `cd /constrained/path && claude --print --tools "Read Grep" --add-dir . "Analyze code"`,
  { cwd: '/constrained/path', encoding: 'utf-8' }
);
```

**Approach 2: Environment Variables**
```typescript
const result = execSync('claude --print "Review"', {
  env: {
    ...process.env,
    ANTHROPIC_API_KEY: apiKey,
    HOME: '/isolated/home',
  },
  cwd: '/constrained/workspace',
});
```

**Approach 3: Linux Namespaces (via unshare)**
```bash
unshare --mount --pid --fork \
  claude --print \
    --dangerously-skip-permissions \
    --add-dir /workspace \
    "Your ask"
```

---

## Rhachet Integration Architecture

### Current Architecture
```typescript
// Current rhachet stitcher forms (domain/objects/Stitcher.ts)
type StitcherForm =
  | 'COMPUTE'   // Procedural logic
  | 'IMAGINE'   // Imagination via any brain (LLM API or agent)
  | 'ROUTE'     // Sequential composition
  | 'FANOUT'    // Parallel composition
  | 'CHOICE'    // Conditional branching
  | 'CYCLE';    // Repetition
```

### Current IMAGINE Stitcher
```typescript
// From domain/objects/StitchStep.ts
interface StitchStepImagine<TStitcher extends GStitcher> {
  form: 'IMAGINE';
  stitchee: keyof TStitcher['threads'];

  // Encode threads into a prompt
  enprompt: (input: { threads: TStitcher['threads'] }) => string | Promise<string>;

  // Invoke imagination (the brain!)
  imagine: (input: string, context: TStitcher['context']) => Promise<string>;

  // Decode the imagined output into a stitch
  deprompt: (input: {
    threads: TStitcher['threads'];
    promptOut: string;
    promptIn: string;
  }) => Pick<Stitch<TStitcher['output']>, 'input' | 'output'>;
}
```

### Proposed Extension: Brain Adapters

**No new stitcher form needed!** The existing `IMAGINE` form already supports any brain type through the `imagine` function. We just need to add new brain adapters alongside the existing `imagineViaOpenAI`:

```typescript
// Current brain adapter (logic/stitch/adapters/imagineViaOpenAI.ts)
export interface ContextOpenAI {
  openai: {
    auth: { key: string };
    llm: { model: ChatModel; output: 'words' | 'json' };
  };
}

export const imagineViaOpenAI = async (
  input: string,
  context: ContextOpenAI,
): Promise<string> => {
  // ... OpenAI API invocation
};

// Proposed: New brain adapter for Claude CLI
export interface ContextClaudeCLI {
  claude: {
    auth: { key: string };
    agent: {
      workdir?: string;
      tools?: string[];  // e.g., ['Read', 'Grep']
      permissions?: 'default' | 'bypassPermissions';
      model?: 'sonnet' | 'opus' | 'haiku';
    };
  };
}

export const imagineViaClaudeCLI = async (
  input: string,
  context: ContextClaudeCLI,
): Promise<string> => {
  const { claude } = context;

  const args = ['--print'];

  if (claude.agent.model) {
    args.push('--model', claude.agent.model);
  }

  if (claude.agent.tools) {
    args.push('--tools', `"${claude.agent.tools.join(' ')}"`);
  }

  if (claude.agent.permissions === 'bypassPermissions') {
    args.push('--dangerously-skip-permissions');
  }

  const cmd = `claude ${args.join(' ')} "${input.replace(/"/g, '\\"')}"`;

  return execSync(cmd, {
    cwd: claude.agent.workdir,
    env: { ...process.env, ANTHROPIC_API_KEY: claude.auth.key },
    encoding: 'utf-8',
    maxBuffer: 10 * 1024 * 1024,
  });
};

// Proposed: Cursor, Aider, or any other agent
export const imagineViaCursor = async (input: string, context: ContextCursor) => {
  // ... cursor CLI invocation
};

export const imagineViaAider = async (input: string, context: ContextAider) => {
  // ... aider CLI invocation
};
```

### Implementation Pattern

Using the existing `IMAGINE` stitcher with different brain adapters:

```typescript
// Example: Code review stitcher using Claude CLI as the brain
const reviewCodeWithClaude: StitchStepImagine<MyStitcher> = {
  form: 'IMAGINE',
  stitchee: 'reviews',

  // Encode threads into a prompt
  enprompt: async ({ threads }) => {
    const code = threads.code[0].output;
    const criteria = threads.criteria[0].output;

    return [
      `Review this code against the following criteria:`,
      criteria,
      '',
      'Code:',
      '```',
      code,
      '```',
      '',
      'Format: BLOCKERS (critical issues) and NITPICKS (minor improvements)',
    ].join('\n');
  },

  // Use Claude CLI brain adapter instead of OpenAI
  imagine: imagineViaClaudeCLI,

  // Decode the output
  deprompt: ({ promptOut }) => {
    const blockers = extractSection(promptOut, 'BLOCKERS');
    const nitpicks = extractSection(promptOut, 'NITPICKS');

    return {
      input: promptOut,
      output: { blockers, nitpicks },
    };
  },
};

// Or use OpenAI brain adapter (existing)
const reviewCodeWithOpenAI: StitchStepImagine<MyStitcher> = {
  form: 'IMAGINE',
  stitchee: 'reviews',

  enprompt: /* same as above */,
  imagine: imagineViaOpenAI,  // Different brain!
  deprompt: /* same as above */,
};

// The choice of brain is just which adapter function you pass to `imagine`!
// The rest of the stitcher (enprompt, deprompt) stays the same.
```

**Key insight**: The brain type is just **which function you pass to the `imagine` field**. No architectural changes needed!

---

## Thought Routes with SOTA Agents

### Example: Prepare â†’ Review â†’ Release

Using existing rhachet composition patterns with Claude CLI brain:

```typescript
// 1. Define imagine stitchers with Claude brain
const generateCode: StitchStepImagine<MyStitcher> = {
  form: 'IMAGINE',
  stitchee: 'proposals',
  enprompt: async ({ threads }) => `Generate code for: ${threads.ask[0].output}`,
  imagine: imagineViaClaudeCLI,  // Use Claude CLI
  deprompt: ({ promptOut }) => ({ input: promptOut, output: promptOut }),
};

const reviewForBlockers: StitchStepImagine<MyStitcher> = {
  form: 'IMAGINE',
  stitchee: 'reviews',
  enprompt: async ({ threads }) => `Review code for BLOCKERS:\n${threads.proposals[0].output}`,
  imagine: imagineViaClaudeCLI,  // Use Claude CLI
  deprompt: ({ promptOut }) => ({ input: promptOut, output: parseReview(promptOut) }),
};

const checkSecurity: StitchStepImagine<MyStitcher> = {
  form: 'IMAGINE',
  stitchee: 'security',
  enprompt: async ({ threads }) => `Security review:\n${threads.proposals[0].output}`,
  imagine: imagineViaClaudeCLI,  // Use Claude CLI
  deprompt: ({ promptOut }) => ({ input: promptOut, output: parseSecurityIssues(promptOut) }),
};

// 2. Compose using existing rhachet patterns

// Parallel attempts (existing FANOUT)
const parallelAttempts = genStitchFanout({
  form: 'FANOUT',
  stitchee: 'proposals',
  fanout: [
    { name: 'attempt1', stitcher: generateCode },
    { name: 'attempt2', stitcher: generateCode },
    { name: 'attempt3', stitcher: generateCode },
  ],
  fanin: (attempts) => attempts, // Collect all
});

// Sequential review steps (existing ROUTE)
const reviewAttempts = genStitchRoute({
  form: 'ROUTE',
  stitchee: 'reviews',
  route: [
    reviewForBlockers,
    checkSecurity,
    checkCoherence,  // Another IMAGINE stitcher
  ],
});

// Select best attempt (existing COMPUTE)
const selectBest: StitchStepCompute<MyStitcher> = {
  form: 'COMPUTE',
  stitchee: 'best',
  invoke: ({ threads }) => {
    const reviews = threads.reviews;
    return {
      input: reviews,
      output: reviews
        .filter(r => r.blockers.length === 0)
        .sort((a, b) => a.nitpicks.length - b.nitpicks.length)[0],
    };
  },
};

// Full route (existing ROUTE composition)
const produceFeature = genStitchRoute({
  form: 'ROUTE',
  route: [
    parallelAttempts,  // 3 parallel attempts with Claude CLI
    reviewAttempts,    // Sequential reviews with Claude CLI
    selectBest,        // Compute to select winner
  ],
});
```

**Key point**: All existing rhachet composition patterns (ROUTE, FANOUT, CYCLE, CHOICE) work unchanged. Only difference: `imagine: imagineViaClaudeCLI` instead of `imagine: imagineViaOpenAI`.

---

## Briefs Integration

Rhachet's **briefs** system maps perfectly to Claude's context:

### Current Briefs System
```bash
# Boot briefs for a role
rhachet briefs boot --role mechanic
# Outputs all markdown files with metadata

# Link briefs from node_modules
rhachet briefs link --role mechanic
# Creates symlinks to role's brief directory
```

### Integration with Claude
```typescript
// 1. Get brief paths from role
const briefPaths = await getBriefPaths(role);

// 2. Mount briefs in Docker
const dockerArgs = briefPaths
  .map(p => `-v ${p}:/briefs/${basename(p)}:ro`)
  .join(' ');

// 3. Or inject as system prompt
const briefContext = await Promise.all(
  briefPaths.map(p => readFile(p, 'utf-8'))
);
const systemPrompt = [
  `Role: ${role.name}`,
  `Context:`,
  ...briefContext,
].join('\n\n');

// 4. Invoke with context
const result = execSync(
  `claude --print --system-prompt "${systemPrompt}" "${ask}"`,
  { cwd: workspace }
);
```

---

## Parallel Attempts Implementation

```typescript
// Existing rhachet pattern
const result = await performInIsolatedThreads({
  role,
  skill,
  input: ask,
  threads: 3, // 3 parallel attempts
});

// Implementation with Claude agents
async function performWithClaudeInParallel(
  ask: string,
  attempts: number
): Promise<Array<{ output: string; tokens: number }>> {
  const promises = Array(attempts)
    .fill(null)
    .map((_, i) =>
      invokeClaude({
        prompt: ask,
        workdir: `/tmp/attempt-${i}`,
        temperature: 0, // Consistent but still vary
      })
    );

  return Promise.all(promises);
}
```

**Cost consideration**: Running 3 parallel attempts with Claude Sonnet 4.5:
- ~$3-15 per complex ask (depending on tokens)
- Mitigated by: configurable attempt count, smaller models for reviews

---

## Self-Review Implementation

```typescript
// Route: Produce â†’ Review â†’ Improve
const selfReviewRoute = genStitchRoute({
  route: [
    // Step 1: Generate
    {
      form: 'AGENT',
      agent: 'claude',
      invoke: (ctx, ask) =>
        claude(`--print "${ask}"`),
    },

    // Step 2: Review own work
    {
      form: 'AGENT',
      agent: 'claude',
      invoke: (ctx, ask) => {
        const artifact = ctx.threads.artifacts[0];
        return claude(
          `--print --session-id ${ctx.sessionId} "Review your previous output against: ${criteria}. Format as BLOCKERS + NITPICKS"`
        );
      },
    },

    // Step 3: Incorporate feedback
    {
      form: 'AGENT',
      agent: 'claude',
      invoke: (ctx, ask) => {
        const review = ctx.threads.reviews[0];
        return claude(
          `--print --session-id ${ctx.sessionId} "Improve your output based on review feedback"`
        );
      },
    },
  ],
});
```

**Note**: Using `--session-id` maintains conversation context across route steps.

---

## Deterministic Guarantees

### Challenge
LLMs are inherently non-deterministic (even at temperature=0, there's variance across API calls).

### Mitigation Strategies

1. **Temperature = 0**
   ```bash
   # Not directly exposed in claude CLI, but controlled via API
   # Reduces variance significantly
   ```

2. **Parallel Attempts + Consensus**
   ```typescript
   // Run 3-5 attempts, select most common output
   const outputs = await runParallelAttempts(ask, 5);
   const consensus = findMostCommon(outputs);
   ```

3. **Deterministic Reviews**
   ```typescript
   // Reviews check for:
   // - Blockers (critical issues)
   // - Nitpicks (minor issues)
   // - Criteria compliance
   // => Accept only outputs that pass all checks
   ```

4. **Rhachet's Slipless Progress**
   ```
   The ratchet mechanism ensures:
   - Can only move forward (no backsliding)
   - Each stitch is validated before appending
   - Failed attempts don't pollute thread
   - Retry with improvements until success
   ```

**Result**: While not 100% deterministic, the combination of low temperature + parallel attempts + strict review gates achieves **reliable, predictable outputs**.

---

## Implementation Complexity Assessment

### ðŸŸ¢ LOW Complexity (The Integration)
- **Brain Adapter Functions**: Just add new functions like `imagineViaClaudeCLI` alongside `imagineViaOpenAI`
- **CLI Invocation**: Standard `child_process.execSync()` usage
- **Context Types**: Define `ContextClaudeCLI` interface with agent config
- **No Architectural Changes**: Existing `IMAGINE` stitcher already supports this!

### ðŸŸ¢ LOW Complexity (Supporting Infrastructure)
- **Docker Integration**: Standard container orchestration (if needed for sandboxing)
- **Brief Mounting**: Standard filesystem operations (already working in rhachet)
- **Environment Variables**: Standard process env configuration

### ðŸŸ¢ LOW Complexity (Already Solved!)
- **Parallel Execution**: âœ“ Already implemented (`performInIsolatedThreads`)
- **Route Composition**: âœ“ Already implemented (`genStitchRoute`, `genStitchFanout`)
- **Thread Management**: âœ“ Already implemented (`Thread`, `Threads`)
- **Observability**: âœ“ Already implemented (`StitchTrail`)
- **enprompt/deprompt**: âœ“ Already part of `IMAGINE` interface

**Conclusion**: This is an **extremely simple integration**. The rhachet architecture was already designed for pluggable brains via the `imagine` function. We just need to add new brain adapter functions - no architectural changes needed!

---

## Concrete Implementation Plan

### Phase 1: Core Brain Adapter (1-2 days)
```typescript
// File: src/logic/stitch/adapters/imagineViaClaudeCLI.ts

import { execSync } from 'child_process';

export interface ContextClaudeCLI {
  claude: {
    auth: { key: string };
    agent: {
      workdir?: string;
      tools?: string[];
      permissions?: 'default' | 'bypassPermissions';
      model?: 'sonnet' | 'opus' | 'haiku';
      outputFormat?: 'text' | 'json';
    };
  };
}

export const imagineViaClaudeCLI = async (
  input: string,
  context: ContextClaudeCLI,
): Promise<string> => {
  // Build CLI args from context
  // Execute via execSync
  // Return output
};
```

### Phase 2: Test with Existing Roles (1-2 days)
```typescript
// Use existing role structure
// Just swap: imagine: imagineViaOpenAI â†’ imagine: imagineViaClaudeCLI
// Test with simple skills first
```

### Phase 3: Context Injection (1-2 days)
```typescript
// Add support for injecting briefs into system prompt
// Add support for tool restrictions
// Test in constrained environments
```

### Phase 4: Docker/Sandboxing (Optional, 2-3 days)
```typescript
// If needed: Create Docker-based execution
// Mount briefs as volumes
// Isolate filesystem access
```

### Phase 5: Additional Brain Adapters (1-2 days each)
```typescript
// imagineViaCursor
// imagineViaAider
// imagineViaAnthropicAPI (direct API vs CLI)
```

**Total Estimate**:
- **Minimal (Claude CLI only)**: 3-6 days
- **Full (+ Docker + other agents)**: 8-15 days

**This is much simpler than originally estimated** because we're not adding new stitcher forms, just new adapter functions!

---

## Risk Assessment

### Technical Risk: ðŸŸ¢ LOW
- All components proven (Docker, CLI, child_process)
- Clear integration points in rhachet architecture
- Fallback to direct API if CLI issues arise

### Integration Risk: ðŸŸ¢ LOW
- Rhachet's stitcher abstraction is perfect for this
- Existing patterns (IMAGINE form) provide template
- Backward compatible (doesn't break existing features)

### Cost Risk: ðŸŸ¡ MEDIUM
- SOTA models expensive (Sonnet 4.5: $3/M input, $15/M output)
- Parallel attempts multiply costs (3x attempts = 3x cost)
- **Mitigation**: Configurable attempts, cost caps, smaller models for reviews

### Maintenance Risk: ðŸŸ¢ LOW
- Claude CLI is stable and well-documented
- Minimal external dependencies
- Can swap agents (claude â†’ cursor â†’ aider) without architectural changes

### Adoption Risk: ðŸŸ¢ LOW
- Brings familiar tools to rhachet users
- "Use your favorite brain" value proposition
- Incremental adoption (existing features unaffected)

---

## Alternative Approaches Considered

### 1. Direct API Integration (OpenAI pattern)
**Pros**: More control, no CLI dependency
**Cons**: Misses CLI-specific features (tool restrictions, permission modes)
**Verdict**: CLI better for this use case

### 2. MCP (Model Context Protocol) Integration
**Pros**: Standardized agent communication
**Cons**: Still emerging, less mature than CLI
**Verdict**: Revisit when MCP stabilizes

### 3. Agent-as-a-Service (HTTP API)
**Pros**: Language-agnostic, networked
**Cons**: Added complexity (server, auth, networking)
**Verdict**: Overkill for local automation

---

## Comparison: Claude CLI vs. Direct API

| Feature | Claude CLI | Direct API |
|---------|------------|------------|
| Tool restrictions | âœ“ Fine-grained | âœ— All or nothing |
| Permission modes | âœ“ Multiple modes | âœ— Not applicable |
| Sandbox support | âœ“ `--dangerously-skip-permissions` | âœ— Manual implementation |
| Session management | âœ“ `--session-id` | âœ“ Manual tracking |
| Streaming | âœ“ `--output-format stream-json` | âœ“ SSE |
| JSON output | âœ“ Built-in | âœ“ API native |
| Setup complexity | ðŸŸ¢ Low (CLI installed) | ðŸŸ¡ Medium (API client) |
| **Best for rhachet?** | **âœ“ YES** | Fallback option |

**Recommendation**: Use CLI for primary integration, keep direct API as fallback.

---

## Answers to Specific Questions

### Q1: Can we leverage Claude via CLI with constrained context?
**A: YES - Multiple proven methods:**
- Docker containers with volume mounts âœ“
- Process isolation with `--add-dir` âœ“
- Tool restrictions with `--tools` / `--allowed-tools` âœ“
- Permission bypass for sandboxes with `--dangerously-skip-permissions` âœ“

### Q2: Docker container execution?
**A: YES - Explicitly supported:**
```bash
docker run \
  -v $(pwd)/.behavior:/app/.behavior:ro \
  -e ANTHROPIC_API_KEY=$KEY \
  anthropic/claude-cli \
  claude --print --dangerously-skip-permissions "Task"
```

### Q3: OpenEnv or similar?
**A: YES - Process isolation works:**
```typescript
execSync('claude --print --add-dir /workspace "Task"', {
  cwd: '/workspace',
  env: { ...isolatedEnv },
});
```

### Q4: Can we guarantee deterministic behavior?
**A: MOSTLY - With mitigations:**
- Not 100% deterministic (LLMs have variance)
- Temperature=0 + parallel attempts + strict reviews â‰ˆ reliable outputs
- Rhachet's ratchet mechanism (slipless progress) ensures forward-only movement

### Q5: Integration complexity?
**A: LOW-MEDIUM - Rhachet is well-architected:**
- Most hard problems already solved (parallelization, composition, observability)
- Main work: thin integration layer for AGENT stitcher form
- Estimated 12-20 days for full implementation

---

## Recommended Next Steps

1. **Prototype (Day 1)**
   ```bash
   # Validate CLI invocation works
   claude --print "Hello!" > /tmp/test.txt
   ```

2. **Docker Test (Day 2)**
   ```bash
   # Validate sandboxed execution
   docker run -v $(pwd):/app -e ANTHROPIC_API_KEY=$KEY \
     anthropic/claude-cli \
     claude --print --dangerously-skip-permissions "List files"
   ```

3. **TypeScript Integration (Day 3-4)**
   ```typescript
   // Build ClaudeClient class
   // Test JSON output parsing
   // Test parallel invocations
   ```

4. **Rhachet Integration (Day 5-10)**
   ```typescript
   // Add AGENT stitcher form
   // Implement prepareContext / invoke / deprompt
   // Test with existing roles
   ```

5. **Real Use Case (Day 11-15)**
   ```bash
   # Implement prepare â†’ review â†’ release route
   # Test with actual coding task
   # Validate outputs meet criteria
   ```

6. **Polish & Document (Day 16-20)**
   ```markdown
   # Write usage guide
   # Add examples to repo
   # Create demo video
   ```

---

## Conclusion

**The wish to harness Claude (and SOTA agents) in rhachet is HIGHLY FEASIBLE - and even simpler than expected!**

### Key Discovery

**Rhachet was already designed for pluggable brains!** The `IMAGINE` stitcher's `imagine` function is exactly the abstraction needed. No architectural changes required.

### What Makes This Simple

1. âœ“ **No new stitcher forms needed** - Just use existing `IMAGINE` with different adapter functions
2. âœ“ **Claude CLI's `--print` mode** - Designed specifically for programmatic invocation
3. âœ“ **Fine-grained control** - Tool restrictions, permission modes, context constraints all supported
4. âœ“ **Docker/process isolation** - Fully supported via `--dangerously-skip-permissions` and `--add-dir`
5. âœ“ **All hard problems solved** - Parallel execution, composition, observability already in rhachet

### The Integration

It's just adding new brain adapter functions:

```typescript
// Current
imagine: imagineViaOpenAI

// Add new adapters
imagine: imagineViaClaudeCLI
imagine: imagineViaCursor
imagine: imagineViaAider
```

That's it! Everything else (enprompt, deprompt, composition, parallelization) already works.

### Risk & Complexity

**Technical risk: ðŸŸ¢ LOW**
- Standard child_process invocation
- No architectural changes
- Proven patterns

**Implementation complexity: ðŸŸ¢ LOW**
- 3-6 days for core Claude CLI adapter
- 8-15 days for full suite (Docker + multiple agents)
- Just adding new functions to `src/logic/stitch/adapters/`

**Value proposition: ðŸŸ¢ HIGH**
- Use any SOTA agent as rhachet's brain
- "Bring your favorite brain" - fulfilled
- Compose deterministic thought routes with non-deterministic agents
- Parallel attempts + automatic review + slipless progress

### Recommendation

**Proceed with implementation immediately.**

Start with Phase 1 (core brain adapter, 1-2 days). This will provide immediate value and validate the approach. Then incrementally add:
- Context injection (briefs, tools, system prompts)
- Optional Docker sandboxing
- Additional agent adapters (cursor, aider, etc.)

The architecture is **perfectly aligned**, the tools are **ready**, and the implementation is **simpler than expected**. This is a natural extension of rhachet's existing design, not a major refactoring.

**Estimated time to working prototype: 1-2 days**
**Estimated time to production-ready: 3-6 days**
