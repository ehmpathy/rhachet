# research: domain terms for brain cost metrics

this document proposes terminology options for the new domain objects required to fulfill the brain cost metrics feature.

objective:
- maximize specificity → eliminate ambiguity & minimize confusion
- maximize intuition → eliminate friction & maximize adoption

to create a ubiquitous language.

---

## new domain objects required

from the wish and vision, we need terms for:

1. **static profile** — the cost & gain characteristics of a brain (rates, context window, benchmarks)
2. **result wrapper** — the object returned from `.ask()` and `.act()` that contains output + metrics
3. **invocation metrics** — size and cost measurements from a single invocation
4. **monetary amount** — a value object for cash costs

---

## terminology research

### 1. static profile (cost & gain of a brain)

#### industry terminology

> [1] "the model card is a means of documenting vital elements of an ml model so users can readily understand the intended use cases, characteristics, behaviors, ethical considerations, and the biases and limitations of a particular ml model" — [techtarget](https://www.techtarget.com/whatis/definition/model-card-in-machine-learning)

> [2] "the full model card specification allows specifying languages, licenses, tags, datasets, metrics, as well as the evaluation results the model obtained" — [huggingface](https://huggingface.co/docs/hub/en/model-cards)

> [3] "benchmark cards are intended to pick up where model cards leave off. they can give you a more contextualized perspective on the model's behavior" — [ibm](https://research.ibm.com/blog/documentation-for-LLM-benchmarks)

#### common terms in the wild

| term               | used for                               | source              |
| ------------------ | -------------------------------------- | ------------------- |
| `model card`       | documentation of model characteristics | huggingface, google |
| `model spec`       | behavioral specification               | openai              |
| `price rates`      | cost rates                             | all providers       |
| `capabilities`     | what the model can do                  | anthropic, openai   |
| `context window`   | token capacity                         | all providers       |
| `knowledge cutoff` | data freshness date                    | all providers       |

#### proposed options

| option         | pros                                                | cons                                           |
| -------------- | --------------------------------------------------- | ---------------------------------------------- |
| `BrainCard`    | aligns with "model card" industry term; short       | "card" implies documentation, not runtime data |
| `BrainSpec`    | aligns with "model spec"; supplier guarantees       | none — precise and formal                      |
| `BrainProfile` | intuitive; "profile" = summary of characteristics   | overloaded in software (user profile, etc.)    |
| `BrainUsage`   | from the wish; implies "how to use"                 | overloaded — could mean consumption vs rates   |
| `BrainRates`   | precise for cost dimension                          | misses the "gain" dimension (benchmarks, etc.) |
| `BrainMenu`    | fun; implies "what you get for what you pay"        | too informal for enterprise                    |

**recommendation**: `BrainSpec`

in industry, **specifications** are what the **supplier guarantees**:
- "this motor is rated to 5000 RPM" — supplier spec
- "this resistor has 1% tolerance" — supplier spec
- "this model has 200k context window" — supplier spec

for a brain, the spec is what the supplier (anthropic, openai, etc.) publishes and guarantees:

| attribute        | who defines it | nature               |
| ---------------- | -------------- | -------------------- |
| context window   | supplier       | guaranteed capacity  |
| price rates      | supplier       | guaranteed cost      |
| benchmarks       | supplier       | claimed performance  |
| knowledge cutoff | supplier       | declared freshness   |

`BrainSpec` = the specifications that the brain supplier publishes and guarantees

---

### 2. result wrapper (output + metrics)

#### industry terminology

> [4] "a better approach is to return a result object that encapsulates the success or failure of the operation. this contains either a value or an error message" — [medium](https://medium.com/@aseem2372005/the-result-pattern-in-c-a-smarter-way-to-handle-errors-c6dee28a0ef0)

> [5] "the result object now becomes a reliable source of truth for the entire application" — [medium](https://medium.com/@elhelw258/unified-api-response-in-net-web-api-bc4bf62c638e)

> [6] "the hard-coded name of result could be whatever sounds sensible—like payload or response" — [shazow](https://shazow.net/posts/how-i-design-json-api-responses/)

#### common terms in the wild

| term         | used for                   | source     |
| ------------ | -------------------------- | ---------- |
| `Result<T>`  | wrapper with success/error | rust, .net |
| `Response`   | api response wrapper       | rest apis  |
| `Output`     | model output               | ml/ai      |
| `Completion` | chat completion response   | openai     |
| `Message`    | response message           | anthropic  |

#### proposed options

| option             | pros                                | cons                                          |
| ------------------ | ----------------------------------- | --------------------------------------------- |
| `BrainResult<T>`   | aligns with Result pattern; generic | "result" implies success/failure, not metrics |
| `BrainResponse<T>` | familiar api pattern                | implies http response                         |
| `BrainOutput<T>`   | clear — what came out of the brain  | could confuse with `TOutput` itself           |
| `BrainReply<T>`    | conversational; clear intent        | less common in api patterns                   |
| `BrainYield<T>`    | implies "what the brain yielded"    | unfamiliar; sounds like generators            |

**recommendation**: `BrainOutput<T>`
- clear semantic: "the output from a brain invocation"
- `.output` property access is natural: `result.output`
- aligns with wish terminology

---

### 3. invocation metrics (size and cost measurements)

#### industry terminology

> [7] "the common usage metrics in llm apis include: requests, input_tokens, output_tokens, total_tokens" — [openai agents sdk](https://openai.github.io/openai-agents-python/usage/)

> [8] "observability dashboards typically display key metrics such as token usage, api call distribution, and model-wise invocation counts" — [zenml](https://www.zenml.io/blog/best-llm-monitoring-tools)

> [9] "it can be fun to include a stats object with performance information" — [shazow](https://shazow.net/posts/how-i-design-json-api-responses/)

#### common terms in the wild

| term        | used for           | source              |
| ----------- | ------------------ | ------------------- |
| `usage`     | token consumption  | openai, anthropic   |
| `metrics`   | measurements       | observability tools |
| `stats`     | statistics         | api responses       |
| `telemetry` | observability data | sdks                |
| `cost`      | monetary spend     | bill systems        |

#### proposed options

| option               | pros                                 | cons                               |
| -------------------- | ------------------------------------ | ---------------------------------- |
| `BrainMetrics`       | generic; covers size + cost          | very generic                       |
| `BrainOutputMetrics` | scoped to output; clear relationship | verbose                            |
| `BrainUsage`         | aligns with openai/anthropic "usage" | conflicts with static profile name |
| `BrainStats`         | short; informal                      | less precise                       |
| `BrainTelemetry`     | implies observability                | overloaded term                    |
| `BrainCost`          | precise for monetary dimension       | misses size dimension              |

**recommendation**: `BrainOutputMetrics` if static profile is `BrainSpec`; else `BrainMetrics`
- pairs naturally with `BrainOutput<T>.metrics`
- clear scope: metrics about the output

---

### 4. monetary amount (price value object)

#### industry terminology

> [10] "money behaves differently from a simple number, and thus should be treated differently. the first and most important aspect is that it should always be composed of an amount and a currency" — [frontstuff](https://frontstuff.io/how-to-handle-monetary-values-in-javascript)

> [11] "instances of money are immutable and each arithmetic operation will return a new instance of the object" — [ts-money](https://github.com/macor161/ts-money)

> [12] "token-based price is how most ai companies charge for their services. prices are typically listed per 1M tokens as the standard unit" — [afternoon.co](https://www.afternoon.co/blog/token-based-pricing-guide)

#### common terms in the wild

| term     | used for             | source            |
| -------- | -------------------- | ----------------- |
| `Money`  | monetary value       | fowler, dinero.js |
| `Price`  | cost of item         | commerce          |
| `Cost`   | expense incurred     | finance           |
| `Rate`   | price per unit       | bills             |
| `Amount` | quantity of currency | banks             |

#### proposed options

| option      | pros                       | cons                                      |
| ----------- | -------------------------- | ----------------------------------------- |
| `Price`     | intuitive; "what it costs" | could imply "list price" vs "actual cost" |
| `Money`     | aligns with fowler pattern | generic; not domain-specific              |
| `Cost`      | what was spent             | could be verb or noun                     |
| `Amount`    | neutral term               | very generic                              |
| `Dollars`   | explicit currency          | assumes usd                               |
| `UsdAmount` | explicit currency          | verbose                                   |

**recommendation**: `Price`
- intuitive for "cost per token"
- aligns with vision: `cost.cash.input: Price`
- short and clear

---

## proposed term set

| concept            | term                 | rationale                                          |
| ------------------ | -------------------- | -------------------------------------------------- |
| static profile     | `BrainSpec`          | supplier-guaranteed specifications                 |
| result wrapper     | `BrainOutput<T>`     | clear; "output from brain"                         |
| invocation metrics | `BrainOutputMetrics` | scoped to output; pairs with `BrainOutput.metrics` |
| monetary amount    | `Price`              | intuitive; short                                   |

---

## relationships

```
BrainAtom ──has──> BrainSpec (1:1 composition)
BrainRepl ──has──> BrainSpec (1:1 composition)

BrainOutput<T>
  ├── output: T
  └── metrics: BrainOutputMetrics
        ├── size: { input, output, cache }
        └── cost: { time, cash }
              └── cash: { input: Price, output: Price, ... }

calcBrainOutputCost ──reads──> BrainSpec.cost.cash
calcBrainOutputCost ──produces──> BrainOutputMetrics.cost.cash
```

---

## how folks commonly talk about these

### static profile

> [13] "gemini 3 pro, grok 4, and llama 4 maverick all feature 1 million token context windows" — [azumo](https://azumo.com/artificial-intelligence/ai-insights/top-10-llms-0625)

> [14] "claude 4 opus leads code benchmarks with 72.5% swe-bench" — [azumo](https://azumo.com/artificial-intelligence/ai-insights/top-10-llms-0625)

> [15] "the knowledge cutoff date is the point in time up to which a large language model received data" — [gradually.ai](https://www.gradually.ai/en/ai-glossary/knowledge-cutoff-date/)

developers talk about models in terms of:
- **context window** (capacity)
- **benchmark scores** (capability)
- **knowledge cutoff** (freshness)
- **price per token** (cost)

### invocation metrics

> [16] "values in the usage section of the response from the llm api are used to determine token usage" — [microsoft](https://learn.microsoft.com/en-us/azure/api-management/llm-token-limit-policy)

> [17] "since llm apis can get expensive fast, tools that track token usage and let you set alerts on spend are recommended" — [zenml](https://www.zenml.io/blog/best-llm-monitoring-tools)

developers talk about invocations in terms of:
- **tokens used** (input, output, cached)
- **cost incurred** (dollars spent)
- **latency** (time elapsed)

---

## citations

1. techtarget — model card definition
2. huggingface — model card specification
3. ibm — benchmark cards
4. medium — result pattern definition
5. medium — result object as source of truth
6. shazow — api response name choices
7. openai agents sdk — usage metrics
8. zenml — observability metrics
9. shazow — stats object
10. frontstuff — money pattern
11. ts-money — immutable money
12. afternoon.co — token-based price
13. azumo — context window terminology
14. azumo — benchmark score terminology
15. gradually.ai — knowledge cutoff definition
16. microsoft — usage section in api response
17. zenml — token usage tracker

---

## sources

- [techtarget model card](https://www.techtarget.com/whatis/definition/model-card-in-machine-learning)
- [huggingface model cards](https://huggingface.co/docs/hub/en/model-cards)
- [ibm benchmark cards](https://research.ibm.com/blog/documentation-for-LLM-benchmarks)
- [result pattern medium](https://medium.com/@aseem2372005/the-result-pattern-in-c-a-smarter-way-to-handle-errors-c6dee28a0ef0)
- [api response design shazow](https://shazow.net/posts/how-i-design-json-api-responses/)
- [openai agents sdk usage](https://openai.github.io/openai-agents-python/usage/)
- [zenml llm monitor](https://www.zenml.io/blog/best-llm-monitoring-tools)
- [frontstuff money pattern](https://frontstuff.io/how-to-handle-monetary-values-in-javascript)
- [ts-money](https://github.com/macor161/ts-money)
- [token-based price](https://www.afternoon.co/blog/token-based-pricing-guide)
- [azumo llm comparison](https://azumo.com/artificial-intelligence/ai-insights/top-10-llms-0625)
- [gradually.ai knowledge cutoff](https://www.gradually.ai/en/ai-glossary/knowledge-cutoff-date/)
- [microsoft llm token limit](https://learn.microsoft.com/en-us/azure/api-management/llm-token-limit-policy)
