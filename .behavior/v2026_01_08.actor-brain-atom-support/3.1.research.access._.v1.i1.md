# research.access.v1.i1

## wish summary

create a demo library for `BrainAtom({ repo: xai, slug: 'grok/code-fast-1' })` following the pattern in `src/_topublish/rhachet-brain-openai`.

---

## remote access 1: xAI API

### description

xAI provides API access to Grok models for text generation, reasoning, and code tasks.

### citations (external)

[1] xAI docs (https://docs.x.ai/docs/overview):
> "Our API makes it easy to harness Grok's intelligence in your projects. Grok is our flagship AI model designed to deliver truthful, insightful answers."

[2] xAI tutorial (https://docs.x.ai/docs/tutorial):
> "Export your API key as an environment variable: `export XAI_API_KEY='your_api_key'`"

[3] xAI tutorial (https://docs.x.ai/docs/tutorial):
> "JavaScript (OpenAI SDK):
> ```javascript
> import OpenAI from 'openai';
> const client = new OpenAI({
>     apiKey: 'your_api_key',
>     baseURL: 'https://api.x.ai/v1'
> });
> ```"

[4] xAI docs (https://docs.x.ai/docs/tutorial):
> "As well as a native xAI Python SDK, the majority of their APIs are fully compatible with the OpenAI and Anthropic SDKs."

### interface contract

| property | value |
|----------|-------|
| base URL | `https://api.x.ai/v1` |
| auth | Bearer token via `XAI_API_KEY` |
| protocol | OpenAI-compatible Chat Completions API |
| request format | JSON with `model`, `messages[]`, `max_tokens` |
| response format | JSON with `choices[].message.content` |

---

## remote access 2: xAI available models

### description

xAI offers multiple Grok models with varying capabilities, context sizes, and pricing.

### citations (external)

[5] xAI models (https://docs.x.ai/docs/models, https://x.ai/api):
> "grok-code-fast-1 - Speedy and economical reasoning model optimized for agentic coding (256K context)"

[6] xAI models (https://docs.x.ai/docs/models):
> "Grok 4 models:
> - `grok-4-07-09` (256K context)
> - `grok-4-fast-non-reasoning` (2M context)
> - `grok-4-fast-reasoning` (2M context)"

[7] xAI models (https://docs.x.ai/docs/models):
> "Grok 4.1 models:
> - `grok-4-1-fast-reasoning` - Frontier model optimized for agentic tool calling with reasoning (2M context)
> - `grok-4-1-fast-non-reasoning` - Fast variant for instant responses without reasoning (2M context)"

[8] xAI models (https://docs.x.ai/docs/models):
> "Grok 3 models:
> - `grok-3-beta` (131K context)
> - `grok-3-mini-beta` (131K context)"

[9] xAI models (https://docs.x.ai/docs/models):
> "Model aliases help users automatically migrate to the next version. `<modelname>` is aliased to the latest stable version."

### model IDs for BrainAtom

| slug | model ID | context | description |
|------|----------|---------|-------------|
| `xai/grok-code-fast-1` | `grok-code-fast-1` | 256K | optimized for agentic coding |
| `xai/grok-3` | `grok-3-beta` | 131K | balanced reasoning |
| `xai/grok-3-mini` | `grok-3-mini-beta` | 131K | fast and cost-effective |
| `xai/grok-4` | `grok-4-07-09` | 256K | advanced reasoning |
| `xai/grok-4-fast` | `grok-4-fast-reasoning` | 2M | frontier with reasoning |

---

## remote access 3: SDK options

### description

multiple SDK options are available for accessing xAI's API from TypeScript/JavaScript.

### citations (external)

[10] xAI tutorial (https://docs.x.ai/docs/tutorial):
> "JavaScript (OpenAI SDK):
> ```javascript
> import OpenAI from 'openai';
> const client = new OpenAI({
>     apiKey: 'your_api_key',
>     baseURL: 'https://api.x.ai/v1'
> });
> ```"

[11] @ai-sdk/xai (https://ai-sdk.dev/providers/ai-sdk-providers/xai):
> "Package Installation: `pnpm add @ai-sdk/xai`"

[12] @ai-sdk/xai (https://ai-sdk.dev/providers/ai-sdk-providers/xai):
> "Provider Setup:
> ```typescript
> import { xai } from '@ai-sdk/xai';
> ```
> For customized configuration:
> ```typescript
> import { createXai } from '@ai-sdk/xai';
> const xai = createXai({
>   apiKey: 'your-api-key',
> });
> ```"

[13] @ai-sdk/xai (https://ai-sdk.dev/providers/ai-sdk-providers/xai):
> "Environment Variables Required: `XAI_API_KEY` - Authentication token for xAI API"

### SDK comparison

| SDK | install | pros | cons |
|-----|---------|------|------|
| `openai` (via baseURL) | `pnpm add openai` | already used in repo, minimal new deps | manual baseURL config |
| `@ai-sdk/xai` | `pnpm add @ai-sdk/xai` | native xAI support, auto model resolution | new dependency, different API |

### recommendation

use **OpenAI SDK with baseURL override** to match existing `rhachet-brain-openai` pattern.

---

## best practices (industry)

### citations (external)

[14] xAI tutorial (https://docs.x.ai/docs/tutorial):
> "Responses include usage tracking with `prompt_tokens`, `completion_tokens`, `total_tokens`, and detailed breakdowns of token types (text, audio, image, cached, reasoning)."

[15] xAI docs (https://docs.x.ai/docs/models):
> "Prompt caching is available for select Grok models including grok-code-fast-1, grok-4, grok-3, grok-3-mini, and grok-3-mini-fast."

### industry best practices

1. **use environment variables for API keys** - never hardcode secrets
2. **implement retry logic** - handle transient failures gracefully
3. **set appropriate timeouts** - prevent hanging requests
4. **validate responses via schema** - ensure type safety at runtime
5. **compose system prompts from briefs** - leverage role context

---

## best practices (repo-internal)

### citations (internal)

[16] `src/_topublish/rhachet-brain-openai/src/atoms/genBrainAtom.ts:91-93`
```ts
      // get openai client from context or create new one
      const openai =
        (context?.openai as OpenAI | undefined) ??
        new OpenAI({ apiKey: process.env.OPENAI_API_KEY });
```

[17] `src/_topublish/rhachet-brain-openai/src/atoms/genBrainAtom.ts:86-88`
```ts
      // compose system prompt from briefs
      const systemPrompt = askInput.role.briefs
        ? await castBriefsToPrompt({ briefs: askInput.role.briefs })
        : undefined;
```

[18] `src/_topublish/rhachet-brain-openai/src/atoms/genBrainAtom.ts:112`
```ts
      // parse output via schema
      return askInput.schema.output.parse({ content });
```

[19] `src/_topublish/rhachet-brain-openai/src/repls/genBrainRepl.ts:96-100`
```ts
  const response = await withRetry(
    withTimeout(async () => thread.run(fullPrompt, { outputSchema }), {
      threshold: { seconds: 60 },
    }),
  )();
```

[20] `src/domain.operations/role/briefs/castBriefsToPrompt.ts:12-24`
```ts
export const castBriefsToPrompt = async (input: {
  briefs: Artifact<typeof GitFile>[];
}): Promise<string> => {
  // resolve all artifacts to get their content
  const contents = await Promise.all(
    input.briefs.map(async (brief) => {
      const file = await brief.get();
      return file?.content;
    }),
  );

  return contents.filter(Boolean).join('\n\n');
};
```

[21] `src/domain.operations/schema/castZodToJsonSchema.ts:13-24`
```ts
export const castZodToJsonSchema = (input: {
  schema: z.ZodSchema;
  target: 'claude' | 'openai';
}): object => {
  // convert based on target SDK
  if (input.target === 'claude') {
    return zodToJsonSchema(input.schema, { $refStrategy: 'root' });
  }

  // openai target
  return zodToJsonSchema(input.schema, { target: 'openAi' });
};
```

### repo-internal best practices

1. **use OpenAI SDK with baseURL** - xAI is OpenAI-compatible [3, 10]
2. **environment variable naming** - use `XAI_API_KEY` [2, 13]
3. **compose briefs via castBriefsToPrompt** - shared utility [17, 20]
4. **schema validation via zod** - runtime type safety [18]
5. **convert zod to json schema** - native structured output [21]
6. **use withRetry + withTimeout** - resilience patterns [19]
7. **fallback client creation** - context?.client ?? new Client() [16]

---

## implementation plan for rhachet-brain-xai

### file structure

```
src/_topublish/rhachet-brain-xai/
  src/
    index.ts                      # exports getBrainAtomsByXAI, genBrainAtom
    atoms/
      genBrainAtom.ts             # BrainAtom factory
      genBrainAtom.integration.test.ts
```

### environment requirements

| variable | description |
|----------|-------------|
| `XAI_API_KEY` | xAI API authentication token |

### dependencies

| package | version | purpose |
|---------|---------|---------|
| `openai` | existing | OpenAI-compatible client with baseURL |

### key implementation details

```typescript
// use OpenAI SDK with xAI baseURL
const openai = new OpenAI({
  apiKey: process.env.XAI_API_KEY,
  baseURL: 'https://api.x.ai/v1',
});

// call chat completions (OpenAI-compatible)
const response = await openai.chat.completions.create({
  model: config.model,  // e.g., 'grok-code-fast-1'
  messages,
});
```

---

## summary

| access | interface | auth | best practice |
|--------|-----------|------|---------------|
| xAI API | OpenAI SDK + baseURL | `XAI_API_KEY` | follow rhachet-brain-openai pattern |

### key insight

xAI's API is **fully OpenAI-compatible** [4, 10]. this means we can reuse the existing OpenAI SDK (`openai` package) with only a `baseURL` override to `https://api.x.ai/v1`. no new SDK dependency needed.

### sources

- [xAI API Overview](https://docs.x.ai/docs/overview)
- [xAI Tutorial](https://docs.x.ai/docs/tutorial)
- [xAI Models and Pricing](https://docs.x.ai/docs/models)
- [@ai-sdk/xai Provider](https://ai-sdk.dev/providers/ai-sdk-providers/xai)
