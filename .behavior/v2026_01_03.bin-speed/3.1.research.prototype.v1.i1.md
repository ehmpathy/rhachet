# prototype research: bun compile performance

## .context

prototyped bun binary compilation to measure actual performance gains and identify remaining bottlenecks.

---

## prototype setup

### files created

```
bin/run.bun.bc              # bun compiled binary with bytecode
src/contract/cli/invoke.bun.entry.ts  # bun entrypoint wrapper
```

### compilation command

```bash
./node_modules/.bin/bun build ./src/contract/cli/invoke.bun.entry.ts \
  --compile --bytecode --outfile ./bin/run.bun.bc
```

compilation time: ~2.6s (bundle: 2.1s, compile: 0.5s)
binary size: **102MB**

---

## benchmark results

### test: `run --skill say-hello`

| implementation | run 1 | run 2 | run 3 | run 4 | run 5 | avg |
|----------------|-------|-------|-------|-------|-------|-----|
| direct shell | 9ms | 17ms | 12ms | 11ms | 6ms | **~11ms** |
| bun bytecode | 537ms | 568ms | 619ms | 580ms | 601ms | **~581ms** |
| node (current) | 2902ms | 2465ms | 2821ms | 2424ms | 3023ms | **~2727ms** |

### test: `init --help` (no config loading)

| implementation | run 1 | run 2 | run 3 | run 4 | run 5 | avg |
|----------------|-------|-------|-------|-------|-------|-----|
| bun bytecode | 500ms | 451ms | 417ms | 349ms | 406ms | **~425ms** |
| node (current) | 1949ms | 2400ms | 1803ms | 1711ms | 1577ms | **~1888ms** |

### baseline measurements

| binary type | avg startup |
|-------------|-------------|
| minimal (console.log only) | **~74ms** |
| commander only | **~110ms** |

---

## overhead analysis

### for `run --skill say-hello`

| component | time | notes |
|-----------|------|-------|
| direct skill execution | ~11ms | baseline |
| **bun binary overhead** | **~570ms** | target: 100ms ‚ùå |
| node binary overhead | ~2716ms | current state |

### improvement achieved

| metric | value |
|--------|-------|
| speedup vs node | **4.7x faster** |
| overhead reduction | 2716ms ‚Üí 570ms |
| remaining gap to 100ms | **470ms** |

---

## bottleneck breakdown

from baseline measurements:

| layer | time added | cumulative |
|-------|------------|------------|
| bun runtime startup | ~74ms | 74ms |
| commander loading | ~36ms | 110ms |
| rhachet logic + config | **~471ms** | 581ms |

the **rhachet logic + config** layer is the bottleneck. this includes:
1. dynamic import of `rhachet.use.ts`
2. registry resolution and role enumeration
3. skill lookup and path resolution

---

## key findings

### ‚úÖ bun compile works

- binary compiles successfully (102MB, ~2.6s compile time)
- dynamic config loading (`rhachet.use.ts`) still works at runtime
- no native module blockers
- 4.7x faster than node

### ‚ùå not fast enough for 100ms target

- bun binary: ~581ms for `run --skill`
- target: 100ms overhead on top of ~11ms direct execution
- actual overhead: 570ms (5.7x over target)

### üîç bottleneck is application logic, not runtime

- bun baseline: ~74ms (under 100ms ‚úì)
- commander + routing: ~110ms (near 100ms ‚úì)
- rhachet config/registry loading: +471ms (the problem)

---

## detailed timing analysis (DEBUG_PERF)

added instrumentation to pinpoint exact bottlenecks:

### timing output

```
[perf] entry.start: 0ms
[perf] entry.beforeImport: 1ms
[perf] entry.afterImport: 395ms      ‚Üê BOTTLENECK: bundled module init
[perf] invoke.start: 1ms
[perf] invoke.beforeGitRoot: 2ms
[perf] invoke.afterGitRoot: 40ms
[perf] invoke.beforeRegistries: 40ms
[perf] invoke.afterRegistries: 45ms  ‚Üê config loading only 5ms!
[perf] invoke.beforeBrains: 45ms
[perf] invoke.afterBrains: 45ms
[perf] invoke.beforeHooks: 45ms
[perf] invoke.afterHooks: 46ms
[perf] invoke.afterAssureUnique: 46ms
[perf] invoke.afterCommandSetup: 68ms
[perf] invoke.beforeParse: 68ms
[perf] entry.done: 536ms
```

### breakdown

| phase | duration | cumulative | notes |
|-------|----------|------------|-------|
| binary startup | 1ms | 1ms | bun runtime init |
| **module initialization** | **394ms** | **395ms** | **855 bundled modules** |
| git root lookup | 38ms | 433ms | filesystem traversal |
| config loading | 5ms | 438ms | rhachet.use.ts parsing |
| brains + hooks | 1ms | 439ms | minimal |
| command setup | 22ms | 461ms | commander registration |
| command execution | ~75ms | 536ms | actual skill run |

### root cause: bundled module initialization

the **394ms** spent in `await import('./invoke')` is NOT the dynamic import itself ‚Äî it's the **initialization of all 855 bundled modules** when the invoke module graph is first accessed.

this happens because:
1. bun bundles all dependencies into a single binary
2. on first import, all module-level code executes
3. even though modules are pre-compiled bytecode, initialization still runs

### hypothesis disproven: rhachet.use.ts is NOT the bottleneck

| hypothesis | expected | actual | verdict |
|------------|----------|--------|---------|
| rhachet.use.ts loading is slow | ~150ms+ | **5ms** | ‚ùå disproven |
| converting to .yml would help | significant | **~5ms max** | ‚ùå not worth it |
| bundled module init is slow | unknown | **394ms** | ‚úÖ confirmed |

**converting to `.yml` config would save at most 5ms** ‚Äî not meaningful.

---

## recommendations (updated based on time analysis)

### strategy 1: minimal entrypoints (high impact)

the 394ms is module init for **855 bundled modules**. most are unused for simple commands like `run --skill`.

create separate minimal binaries:

```
bin/run.bun.bc          # full CLI (current: 855 modules, 102MB)
bin/run-skill.bun.bc    # minimal: commander + skill executor only
```

expected gain: if reduced to ~100 modules, could achieve ~50ms init

### strategy 2: code split / tree shake

analyze which modules are actually needed for each command:

| command | modules needed | current bundled |
|---------|----------------|-----------------|
| `run --skill` | ~50 | 855 |
| `roles boot` | ~100 | 855 |
| `ask` | ~400 | 855 |

use bun's bundler options to exclude unused code paths.

### strategy 3: lazy load within bundle

even with bundled binary, we can defer heavy subcommand setup:

```ts
// before: all subcommands registered upfront
invokeAsk({ program, ... });
invokeAct({ program, ... });

// after: minimal shell, lazy load on match
program.command('ask').action(async () => {
  const { handleAsk } = await import('./handlers/ask');
  await handleAsk();
});
```

this won't reduce bundled modules but defers their init.

### strategy 4: accept ~400ms as realistic target

if the full CLI must bundle all 855 modules:
- 400ms is 6.8x faster than node (2727ms)
- 400ms may be acceptable for non-hook use cases
- for hooks (5s timeout), 400ms leaves 4.6s for actual work

### ‚ùå strategies that won't help

| strategy | why not |
|----------|---------|
| convert rhachet.use.ts to .yml | only saves 5ms |
| cache config to disk | only saves 5ms |
| optimize git root lookup | only saves 38ms |

---

## conclusion

bun compile provides **significant improvement** (4.7x faster) but is **not sufficient alone** to meet the 100ms target. the bottleneck is now **bundled module initialization**:

| bottleneck | time | status |
|------------|------|--------|
| ~~node.js JIT~~ | ~~2000ms+~~ | ‚úÖ solved by bun |
| ~~module resolution~~ | ~~500ms+~~ | ‚úÖ solved by bundle |
| ~~rhachet.use.ts loading~~ | ~~150ms+~~ | ‚úÖ only 5ms |
| **855 bundled modules init** | **394ms** | ‚ùå the bottleneck |

### key insight

rhachet's actual logic is fast (~68ms). the problem is that bun must initialize all 855 bundled modules before any code runs. this is inherent to how bundlers work ‚Äî all module-level code executes on first access.

### recommended next steps

1. ‚úÖ ~~profile rhachet startup~~ ‚Äî done, bottleneck identified
2. prototype minimal `run --skill` binary with fewer modules
3. measure if reduced module count achieves 100ms target
4. if not achievable, accept ~400ms as realistic and document tradeoffs
